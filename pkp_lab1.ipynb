{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-szoverfi/BiblAI/blob/main/pkp_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labor 1\n",
        "\n",
        "# Bevezetés a CUDA GPU programozásba\n",
        "\n",
        "## Mi a párhuzamos programozás?\n",
        "\n",
        "A párhuzamos programozás olyan programozási paradigma, ahol több számítási feladat egyidejűleg, egymással párhuzamosan fut. Hagyományos, szekvenciális programozás esetén a program utasításai egymás után, lépésről lépésre hajtódnak végre. Ezzel szemben a párhuzamos programozás lehetővé teszi, hogy több utasítás egyidejűleg fusson.\n",
        "\n",
        "## Miért van szükség párhuzamos programozásra?\n",
        "\n",
        "A processzorteljesítmény növelése az évek során elérte fizikai korlátait (órajel, hőtermelés). Az egymagos processzorok teljesítménye nem növelhető a végtelenségig, így többmagos processzorokat kezdtek gyártani. Bizonyos feladatok természetüknél fogva párhuzamosíthatók (pl. képfeldolgozás, mátrixműveletek, szimulációk), amelyek hatékonyan felgyorsíthatók párhuzamos feldolgozással.\n",
        "\n",
        "## GPU-k és a CUDA szerepe\n",
        "\n",
        "A grafikus processzorok (GPU-k) eredetileg a számítógépes grafikához készültek, de felismerték, hogy bizonyos számítási feladatok (különösen azok, amelyek sok adaton ugyanazt a műveletet végzik) sokkal gyorsabban futhatnak rajtuk. A GPU-k több ezer egyszerűbb számítási magot tartalmaznak, szemben a CPU-k néhány komplex magjával.\n",
        "\n",
        "A [GPGPU](https://www.gigabyte.com/Glossary/gpgpu) rövidítés a \"General Purpose Graphics Processing Unit\"-ra utal, ami egy olyan számítási technológia, amely során a grafikus kártyák (GPU-k) számítási kapacitását használjuk általános célú számítások végrehajtására. Mint láttuk, a GPU-k eredetileg kifejezetten grafikus feladatok hatékony megoldására lettek tervezve, mint például a képfeldolgozás vagy 3D grafika. Azonban, az elmúlt években a GPU-k egyre inkább beépültek az általános célú számítások világába is.\n",
        "\n",
        "A GPGPU technológia alkalmazása lehetővé teszi, hogy a GPU-k nagy számítási kapacitását felhasználják olyan feladatok elvégzésére, mint például a gépi tanulás, a kriptográfiai műveletek, a tudományos szimulációk vagy a nagy adathalmazok feldolgozása. A GPGPU technológia használata jelentősen felgyorsíthatja ezeket a számítási feladatokat, és csökkentheti azok elvégzésének idejét.\n",
        "\n",
        "Az NVIDIA 2007-ben bemutatta a CUDA (Compute Unified Device Architecture) platformot, amely lehetővé teszi a programozók számára, hogy a GPU-kat általános célú számításokra is használhassák (GPGPU - General-Purpose computing on Graphics Processing Units).\n",
        "\n",
        "## Heterogén párhuzamos programozás\n",
        "\n",
        "A CUDA programozást heterogén párhuzamos programozásnak is nevezik, mert:\n",
        "\n",
        "1. **Heterogén rendszer**: A CPU (host) és a GPU (device) együttműködve oldják meg a feladatot\n",
        "2. **Különböző architektúrák**: A CPU és a GPU eltérő architektúrával és memóriarendszerrel rendelkezik\n",
        "3. **Eltérő feladatkörök**: A CPU általában a szekvenciális részeket, a GPU a párhuzamosítható részeket hajtja végre\n",
        "\n"
      ],
      "metadata": {
        "id": "-vk-2uPuPL6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Runtime API\n",
        "\n",
        "\n",
        "A [CUDA Runtime API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html) egy függvénykönyvtárból és a C++ szintaxis egyszerű kiegészítéséből áll.\n",
        "\n",
        "A CUDA programokat `*.cu` (nem `*.c` vagy `*.cpp`) kiterjesztésű állományokban írjuk. Mint meglátjuk, alapvetően C++ kódot írünk, melyet néha kiegészíthetünk gyorsítón futtatandó programrészletekkel, úgynevezett \"CUDA kernelekkel\".\n",
        "\n",
        "Az alábbi kódrészlet egy tökéletesen működő CUDA program, csak éppenséggel még nem tartalmaz gyorsító specifikus kódot.\n",
        "\n",
        "```cpp\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    std::cout << \"Hello World!\" << std::endl;\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "Ha a programunkban szeretnénk kihasználni a GPU számítási kapacitását lehetőségeit is, akkor GPU kódot is írnunk kell. Ez a számításokhoz szükséges adatokat előkészíti, átmásolja, meghívja a GPU kernelt, majd az adatokat visszamásolja. A CUDA forráskódok általában keverten tartalmazzák a CPU, és GPU kódokat.\n",
        "\n",
        "A GPU-n futó számítást úgynevezett a fentebb említett kernel függvények megadásával tudjuk megvalósítani. Ezek a `__global__` előtaggal rendelkező függvények.\n",
        "\n",
        "### Kompilálás és futtatás\n",
        "\n",
        "A CUDA (`*.cu` kiterjesztésű) programjaink kompilálásához, használjuk a következő parancsot:  \n",
        "\n",
        "```\n",
        "!nvcc mysurcefile.cu -o programname\n",
        "```\n",
        "\n",
        "majd sikeres kompilálás esetében, futtatáshoz:\n",
        "```\n",
        "!./programname\n",
        "```"
      ],
      "metadata": {
        "id": "ikVGiziWBV53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA program általános szerkezete\n",
        "\n",
        "A CUDA programok speciális felépítéssel rendelkeznek, ami a heterogén rendszer sajátosságaiból adódik. Az alábbiakban megnézzük a tipikus CUDA program szerkezetét és a főbb lépéseket.\n",
        "\n",
        "## 1. Program inicializálás és feladatmeghatározás\n",
        "\n",
        "Minden CUDA program a host (CPU) oldalon kezdődik, ahol:\n",
        "- Meghatározzuk a feladat méretét (pl. feldolgozandó elemek száma)\n",
        "- Inicializáljuk a bemeneti adatokat\n",
        "- Kiszámoljuk a memória igényeket\n",
        "\n",
        "```c\n",
        "int n = 1000000;  // Elemek száma\n",
        "size_t size = n * sizeof(float);  // Szükséges memória mérete bájtokban\n",
        "```\n",
        "\n",
        "## 2. Memória kezelés a heterogén rendszerben\n",
        "\n",
        "Kulcsfontosságú megérteni, hogy a CPU és GPU külön memóriaterülettel rendelkezik, így explicit memóriakezelésre van szükség:\n",
        "\n",
        "### a) Host memória foglalás (CPU oldal)\n",
        "```c\n",
        "float *h_input = (float*)malloc(size);\n",
        "float *h_output = (float*)malloc(size);\n",
        "\n",
        "// Adatok inicializálása\n",
        "for (int i = 0; i < n; i++) {\n",
        "    h_input[i] = rand() / (float)RAND_MAX;\n",
        "}\n",
        "```\n",
        "\n",
        "### b) Device memória foglalás (GPU oldal)\n",
        "```c\n",
        "float *d_input = NULL;\n",
        "float *d_output = NULL;\n",
        "cudaMalloc((void**)&d_input, size);\n",
        "cudaMalloc((void**)&d_output, size);\n",
        "```\n",
        "\n",
        "### c) Adatok másolása host-ról device-ra\n",
        "```c\n",
        "cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "```\n",
        "\n",
        "## 3. Kernel definíció\n",
        "\n",
        "A kernel a GPU-n futó függvény, amelyet a `__global__` kulcsszóval jelölünk:\n",
        "\n",
        "```c\n",
        "__global__ void processData(float *input, float *output, int n) {\n",
        "    // Egyedi szálazonosító számítása\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    // Ellenőrzés, hogy a szál érvényes adatelemen dolgozik-e\n",
        "    if (idx < n) {\n",
        "        // Tényleges munka elvégzése (példa: érték duplázása)\n",
        "        output[idx] = 2.0f * input[idx];\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "## 4. Végrehajtási konfiguráció és kernel indítás\n",
        "\n",
        "A kernel indításakor meg kell határozni a végrehajtási konfigurációt (hogyan szerveződnek a szálak blokkokba, a blokkok egy rácsba (grid)):\n",
        "\n",
        "```c\n",
        "// Blokkméret meghatározása (szálak száma blokkonként)\n",
        "int threadsPerBlock = 256;\n",
        "\n",
        "// Blokkok számának kiszámítása\n",
        "// Felfelé kerekítünk, hogy minden adatelemhez jusson szál\n",
        "int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "// Kernel indítása a megadott konfigurációval\n",
        "processData<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, n);\n",
        "\n",
        "// Aszinkron végrehajtás - megvárjuk a befejezést\n",
        "cudaDeviceSynchronize();\n",
        "```\n",
        "\n",
        "## 5. Eredmények visszaolvasása\n",
        "\n",
        "A feldolgozás után az eredményeket vissza kell másolni a GPU-ról a CPU memóriába:\n",
        "\n",
        "```c\n",
        "cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost);\n",
        "```\n",
        "\n",
        "## 6. Eredmények feldolgozása és erőforrások felszabadítása\n",
        "\n",
        "A CPU oldalon feldolgozzuk az eredményeket, majd felszabadítjuk a lefoglalt erőforrásokat:\n",
        "\n",
        "```c\n",
        "// Eredmények feldolgozása (pl. ellenőrzés)\n",
        "for (int i = 0; i < 10; i++) {\n",
        "    printf(\"Input: %f, Output: %f\\n\", h_input[i], h_output[i]);\n",
        "}\n",
        "\n",
        "// Erőforrások felszabadítása\n",
        "cudaFree(d_input);\n",
        "cudaFree(d_output);\n",
        "free(h_input);\n",
        "free(h_output);\n",
        "```\n",
        "\n",
        "## 7. Hibakezelés (jó gyakorlat)\n",
        "\n",
        "A CUDA API hívások hibakódot adnak vissza, amit érdemes ellenőrizni:\n",
        "\n",
        "```c\n",
        "cudaError_t err = cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "if (err != cudaSuccess) {\n",
        "    printf(\"CUDA error: %s\\n\", cudaGetErrorString(err));\n",
        "    // Hibakezelés...\n",
        "}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hz1yiTaVTck0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Szálazonosító számítása a CUDA-ban\n",
        "\n",
        "### Egyedi szálazonosítók működése\n",
        "\n",
        "A CUDA architektúrában minden szálnak szüksége van egy egyedi azonosítóra, hogy tudja, melyik adatelemen kell dolgoznia. Ez az azonosító kiszámítása kulcsfontosságú a párhuzamos végrehajtás során. A CUDA hierarchikus modellben gondolkodik: a szálak blokkokba vannak szervezve, a blokkok pedig rácsot (grid) alkotnak.\n",
        "\n",
        "Az egyedi globális szálazonosító (global thread ID) kiszámítása a következő képlettel történik 1D szervezás esetében:\n",
        "\n",
        "```\n",
        "globalId = blockIdx.x * blockDim.x + threadIdx.x\n",
        "```\n",
        "\n",
        "Ahol:\n",
        "- `blockIdx.x`: Az aktuális blokk indexe a rácsban\n",
        "- `blockDim.x`: A blokkon belüli szálak száma (szálak per blokk)\n",
        "- `threadIdx.x`: A szál indexe a blokkon belül\n",
        "\n",
        "### Példák az 1D azonosító számításra\n",
        "\n",
        "- Ha 2 blokkunk van, egyenként 3 szállal:\n",
        "  - 0. blokk, 0. szál: `0 * 3 + 0 = 0`\n",
        "  - 0. blokk, 1. szál: `0 * 3 + 1 = 1`\n",
        "  - 0. blokk, 2. szál: `0 * 3 + 2 = 2`\n",
        "  - 1. blokk, 0. szál: `1 * 3 + 0 = 3`\n",
        "  - 1. blokk, 1. szál: `1 * 3 + 1 = 4`\n",
        "  - 1. blokk, 2. szál: `1 * 3 + 2 = 5`\n",
        "\n",
        "\n",
        "Ez a számítási modell biztosítja, hogy minden szál pontosan tudja, melyik adatelemen kell dolgoznia, függetlenül attól, hogy hány blokkot és szálat használunk a párhuzamos végrehajtáshoz.\n",
        "\n",
        "\n",
        "Késobbiekben majd megltájuk, hogy például kétdimenziós (pl. mátrixműveleteknél) szervezés esetében is tudunk mindig linearizálni, egyedi azonosítot számítani:\n",
        "\n",
        "```c\n",
        "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "int idx = row * width + col;  // Linearizált index\n",
        "```\n"
      ],
      "metadata": {
        "id": "MK-ZXdmySc9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Példa: Teljes CUDA program a vektorok összeadására\n",
        "\n",
        "Két vektor elemeinek összegzése párhuzamosan CUDA-val:\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// GPU kernel - minden szál egy elemet dolgoz fel\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000;\n",
        "    int size = n * sizeof(int);\n",
        "    \n",
        "    // Host memória foglalása\n",
        "    int *h_a = (int *)malloc(size);\n",
        "    int *h_b = (int *)malloc(size);\n",
        "    int *h_c = (int *)malloc(size);\n",
        "    \n",
        "    // Vektorok inicializálása\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i;\n",
        "    }\n",
        "    \n",
        "    // Device memória foglalása\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "    \n",
        "    // Adatok másolása a host-ról a device-ra\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // Kernel indítása 256 szállal blokkonként\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    \n",
        "    // Eredmény visszamásolása a device-ról a host-ra\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // Eredmény ellenőrzése\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "    \n",
        "    // Memória felszabadítása\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    \n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "A CUDA programozás alapelvei a példában fellelhetőek:\n",
        "1. Szétválasztjuk a kódot CPU (host) és GPU (device) részekre\n",
        "2. A GPU kódot speciális `__global__` kulcsszóval jelöljük (kernel)\n",
        "3. Memóriát foglalunk mindkét eszközön, és explicit másolással kommunikálunk\n",
        "4. Meghatározzuk a párhuzamosítás szintjét (hány blokk és hány szál/blokk)\n",
        "\n",
        "A CUDA előnye, hogy C nyelvi környezetben programozhatunk, minimális nyelvi kiterjesztésekkel, miközben kihasználjuk a GPU-k párhuzamos feldolgozási képességeit."
      ],
      "metadata": {
        "id": "xCxjHelCPdjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "A Google Colaboratory (röviden Colab) egy ingyenes online platform, amely lehetővé teszi a felhasználók számára a (főleg) Python programozási nyelv interaktív környezetében történő munkavégzését. Az egyik fő előnye, hogy ingyenes GPU és TPU (Tensor Processing Unit) számítási erőforrásokat biztosít a felhasználók számára, azzal a cállal, hogy lehetővé tegye a nagyobb adatméretű és bonyolultabb gépi tanulási és adatelemzési feladatok végrehajtását.\n",
        "\n",
        "Az GPU erőforrások igénybevétele érdekében, a felhasználóknak a futásidejű környezet típusát kell áttálítsa. Ehhez, a `Runtime/Change runtime` menűpontban válasszuk ki, hogy `GPU`."
      ],
      "metadata": {
        "id": "RDNbKVlU9cMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `GPU` elérhetőségét teszteln tudjuk a következő kóddal:"
      ],
      "metadata": {
        "id": "LH1eSOFi_g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j03fCHP_PoQ",
        "outputId": "eba9b29f-a689-4ca2-ffa6-97157d9deaae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Nvidia kompájler verziójának lekérése:"
      ],
      "metadata": {
        "id": "SxGnDTAs_51e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hxdSMs37ZtV",
        "outputId": "690201bf-8ec3-4921-ed6c-cfb3ab597cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A kód cellákkban csak Python kód futtatható direkt modon. Ezért, [%%writefile magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) parancsal fogjuk kiírni a lemezre a programjainkat, majd ezeket más kódcellákban kompiláljuk és futtatjuk.\n",
        "\n",
        "Például, az alábbi példaprogram GPU-n végzi el két szám összeadását."
      ],
      "metadata": {
        "id": "6BAs6WrnAA7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vecadd.cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void add(int a, int b, int* c)\n",
        "{\n",
        "    *c = a + b;\n",
        "    return;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int c;\n",
        "    int* dev_c;\n",
        "\n",
        "\t  //memória foglalás a GPU-n\n",
        "    cudaMalloc((void**)&dev_c, sizeof(int) );\n",
        "\n",
        "    add<<<1,1>>>(1, 2, dev_c);\n",
        "\n",
        "    cudaMemcpy(&c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"a + b = %d\\n\", c);\n",
        "\n",
        "    //lefolglat memória felszabadítása\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9JO5bt7hrW",
        "outputId": "c6d6d181-0b61-4765-fee3-86d5497b0c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "És íme meg is jelenik a `vecadd.cu` állomány:"
      ],
      "metadata": {
        "id": "um6CYayyAxIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsq0-uVN9Gbo",
        "outputId": "5949dafc-e028-4430-c994-867de7bde944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompilálás:"
      ],
      "metadata": {
        "id": "lPeatuhnA6Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vecadd.cu"
      ],
      "metadata": {
        "id": "B8gcA_rP9Lrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellenörizzük ha megjelent a futtatható bináris program (`a.out`):"
      ],
      "metadata": {
        "id": "HBKgJTrFA-Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0qF_LNk9P_I",
        "outputId": "ee78c1ee-ce65-4476-bdf7-a1afd074842f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  sample_data  vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Futtatás:"
      ],
      "metadata": {
        "id": "0GJCibQSBJer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lngC1HH79R7N",
        "outputId": "49629419-8b0c-415b-e0c2-69ad00b926f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feladatok\n",
        "\n",
        "1. Írjunk egy CUDA programot, mely a [`cudaError_t cudaGetDeviceCount (int * count)`](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f), [`cudaError_t cudaGetDeviceProperties (struct cudaDeviceProp * prop, int device )`](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0) függvények segítségével, kiírja a CUDA kompatibilis GPU főbb paramétereit.\n",
        "A jellemzőket tartalmazó `cudaDeviceProp` struktúra definíciója a következő:\n",
        "\n",
        "  ```cpp\n",
        "  struct cudaDeviceProp {\n",
        "                char name[256];\n",
        "                cudaUUID_t uuid;\n",
        "                size_t totalGlobalMem;\n",
        "                size_t sharedMemPerBlock;\n",
        "                int regsPerBlock;\n",
        "                int warpSize;\n",
        "                size_t memPitch;\n",
        "                int maxThreadsPerBlock;\n",
        "                int maxThreadsDim[3];\n",
        "                int maxGridSize[3];\n",
        "                int clockRate;\n",
        "                size_t totalConstMem;\n",
        "                int major;\n",
        "                int minor;\n",
        "                size_t textureAlignment;\n",
        "                size_t texturePitchAlignment;\n",
        "                int deviceOverlap;\n",
        "                int multiProcessorCount;\n",
        "                int kernelExecTimeoutEnabled;\n",
        "                int integrated;\n",
        "                int canMapHostMemory;\n",
        "                int computeMode;\n",
        "                int maxTexture1D;\n",
        "                int maxTexture1DMipmap;\n",
        "                int maxTexture1DLinear;\n",
        "                int maxTexture2D[2];\n",
        "                int maxTexture2DMipmap[2];\n",
        "                int maxTexture2DLinear[3];\n",
        "                int maxTexture2DGather[2];\n",
        "                int maxTexture3D[3];\n",
        "                int maxTexture3DAlt[3];\n",
        "                int maxTextureCubemap;\n",
        "                int maxTexture1DLayered[2];\n",
        "                int maxTexture2DLayered[3];\n",
        "                int maxTextureCubemapLayered[2];\n",
        "                int maxSurface1D;\n",
        "                int maxSurface2D[2];\n",
        "                int maxSurface3D[3];\n",
        "                int maxSurface1DLayered[2];\n",
        "                int maxSurface2DLayered[3];\n",
        "                int maxSurfaceCubemap;\n",
        "                int maxSurfaceCubemapLayered[2];\n",
        "                size_t surfaceAlignment;\n",
        "                int concurrentKernels;\n",
        "                int ECCEnabled;\n",
        "                int pciBusID;\n",
        "                int pciDeviceID;\n",
        "                int pciDomainID;\n",
        "                int tccDriver;\n",
        "                int asyncEngineCount;\n",
        "                int unifiedAddressing;\n",
        "                int memoryClockRate;\n",
        "                int memoryBusWidth;\n",
        "                int l2CacheSize;\n",
        "                int persistingL2CacheMaxSize;\n",
        "                int maxThreadsPerMultiProcessor;\n",
        "                int streamPrioritiesSupported;\n",
        "                int globalL1CacheSupported;\n",
        "                int localL1CacheSupported;\n",
        "                size_t sharedMemPerMultiprocessor;\n",
        "                int regsPerMultiprocessor;\n",
        "                int managedMemory;\n",
        "                int isMultiGpuBoard;\n",
        "                int multiGpuBoardGroupID;\n",
        "                int singleToDoublePrecisionPerfRatio;\n",
        "                int pageableMemoryAccess;\n",
        "                int concurrentManagedAccess;\n",
        "                int computePreemptionSupported;\n",
        "                int canUseHostPointerForRegisteredMem;\n",
        "                int cooperativeLaunch;\n",
        "                int cooperativeMultiDeviceLaunch;\n",
        "                int pageableMemoryAccessUsesHostPageTables;\n",
        "                int directManagedMemAccessFromHost;\n",
        "                int accessPolicyMaxWindowSize;\n",
        "            }\n",
        "   ```\n",
        "\n",
        "2. Írjunk egy \"Hello, World\" CUDA kernelt, melyben minden szál kiírja az [egyedi azonosítóját](https://blog.usejournal.com/cuda-thread-indexing-fb9910cba084). Hívjuk meg a kernelt különböző rács és blokk konfigurációkkal. Használjuk a [cudaError_t cudaDeviceSynchronize ( void )](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d) függvényt a kernel hívás bevárására.\n",
        "\n",
        "3. Futtasuk a két tömb összeadása példát.\n",
        "4. Készítsünk CUDA programot, amely egy vektort megszoroz egy konstans értékkel, majd megkeresi a vektor legnagyobb értékét.\n",
        "\n",
        "  **Specifikáció**:\n",
        "  - Hozzunk létre egy 100000 elemű, véletlenszámokat tartalmazó vektort\n",
        "  - A konstans szorzó értéke legyen 2.5\n",
        "  - Írjunk kernelt a vektor konstanssal való szorzásához\n",
        "  - A maximumot egyelőre a CPU oldalon keressük meg a szorzás után\n",
        "\n",
        "  **Lépések**:\n",
        "  1. Hozzunk létre és inicializáljunk egy vektort a host (CPU) oldalon\n",
        "  2. Foglaljunk memóriát a device (GPU) oldalon\n",
        "  3. Másoljuk az adatokat a host-ról a device-ra\n",
        "  4. Implementáljunk és indítsunk egy kernelt a vektor szorzásához\n",
        "  5. Másoljuk vissza az eredményt a device-ról a host-ra\n",
        "  6. Keressük meg a vektor legnagyobb értékét a CPU-n\n",
        "  7. Írjuk ki az eredményt és szabadítsuk fel az erőforrásokat\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xnd_G4H09VNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile device_props.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "    int deviceCount;\n",
        "    cudaError_t err = cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"Hiba a GPU-k lekérdezésekor: \" << cudaGetErrorString(err) << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    std::cout << \"CUDA kompatibilis GPU-k száma: \" << deviceCount << std::endl;\n",
        "\n",
        "    for (int i = 0; i < deviceCount; i++) {\n",
        "        cudaDeviceProp prop;\n",
        "        cudaGetDeviceProperties(&prop, i);\n",
        "\n",
        "        std::cout << \"\\nGPU #\" << i << \": \" << prop.name << std::endl;\n",
        "        std::cout << \"   CUDA Compute Capability: \" << prop.major << \".\" << prop.minor << std::endl;\n",
        "        std::cout << \"   Összes globális memória: \" << prop.totalGlobalMem / (1024 * 1024) << \" MB\" << std::endl;\n",
        "        std::cout << \"   Osztott memória blokk/SM: \" << prop.sharedMemPerBlock / 1024 << \" KB\" << std::endl;\n",
        "        std::cout << \"   Regiszterek blokk/SM: \" << prop.regsPerBlock << std::endl;\n",
        "        std::cout << \"   Warp méret: \" << prop.warpSize << std::endl;\n",
        "        std::cout << \"   Max. szál/blokk: \" << prop.maxThreadsPerBlock << std::endl;\n",
        "        std::cout << \"   Max. blokk dimenziók: [\" << prop.maxThreadsDim[0] << \", \" << prop.maxThreadsDim[1] << \", \" << prop.maxThreadsDim[2] << \"]\" << std::endl;\n",
        "        std::cout << \"   Max. grid méret: [\" << prop.maxGridSize[0] << \", \" << prop.maxGridSize[1] << \", \" << prop.maxGridSize[2] << \"]\" << std::endl;\n",
        "        std::cout << \"   Órajel: \" << prop.clockRate / 1000 << \" MHz\" << std::endl;\n",
        "        std::cout << \"   Multiprocesszorok száma: \" << prop.multiProcessorCount << std::endl;\n",
        "        std::cout << \"   PCI bus ID: \" << prop.pciBusID << std::endl;\n",
        "        std::cout << \"   PCI device ID: \" << prop.pciDeviceID << std::endl;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2gVbGTM4DHl",
        "outputId": "2483e73c-05e1-4f6a-ea3c-5e5fa9e52465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing device_props.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 device_props.cu"
      ],
      "metadata": {
        "id": "HgDNyDyS4NMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j1a-BUU4Ss5",
        "outputId": "f606b80a-9285-40d8-eb15-5bf64550c5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA kompatibilis GPU-k száma: 1\n",
            "\n",
            "GPU #0: Tesla T4\n",
            "   CUDA Compute Capability: 7.5\n",
            "   Összes globális memória: 15095 MB\n",
            "   Osztott memória blokk/SM: 48 KB\n",
            "   Regiszterek blokk/SM: 65536\n",
            "   Warp méret: 32\n",
            "   Max. szál/blokk: 1024\n",
            "   Max. blokk dimenziók: [1024, 1024, 64]\n",
            "   Max. grid méret: [2147483647, 65535, 65535]\n",
            "   Órajel: 1590 MHz\n",
            "   Multiprocesszorok száma: 40\n",
            "   PCI bus ID: 0\n",
            "   PCI device ID: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_world_kernel.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void hello_world_kernel() {\n",
        "    int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    printf(\"Hello from thread %d\\n\", threadId);\n",
        "}\n",
        "\n",
        "void launch_kernel(int num_blocks, int num_threads_per_block) {\n",
        "    std::cout << \"Konfiguráció: \" << num_blocks << \" blokk, \" << num_threads_per_block << \" szál/blokk\" << std::endl;\n",
        "    hello_world_kernel<<<num_blocks, num_threads_per_block>>>();\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    launch_kernel(1, 1);\n",
        "    launch_kernel(2, 4);\n",
        "    launch_kernel(4, 16);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmh2mtAqw_zZ",
        "outputId": "6daa2a74-bc14-4a9a-df73-db2ce94b712e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello_world_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 hello_world_kernel.cu"
      ],
      "metadata": {
        "id": "EejldDcwv07g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZpV7BgEv89A",
        "outputId": "887d6939-e4cb-4681-b6fc-043f5768d240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Konfiguráció: 1 blokk, 1 szál/blokk\n",
            "Hello from thread 0\n",
            "Konfiguráció: 2 blokk, 4 szál/blokk\n",
            "Hello from thread 0\n",
            "Hello from thread 1\n",
            "Hello from thread 2\n",
            "Hello from thread 3\n",
            "Hello from thread 4\n",
            "Hello from thread 5\n",
            "Hello from thread 6\n",
            "Hello from thread 7\n",
            "Konfiguráció: 4 blokk, 16 szál/blokk\n",
            "Hello from thread 0\n",
            "Hello from thread 1\n",
            "Hello from thread 2\n",
            "Hello from thread 3\n",
            "Hello from thread 4\n",
            "Hello from thread 5\n",
            "Hello from thread 6\n",
            "Hello from thread 7\n",
            "Hello from thread 8\n",
            "Hello from thread 9\n",
            "Hello from thread 10\n",
            "Hello from thread 11\n",
            "Hello from thread 12\n",
            "Hello from thread 13\n",
            "Hello from thread 14\n",
            "Hello from thread 15\n",
            "Hello from thread 16\n",
            "Hello from thread 17\n",
            "Hello from thread 18\n",
            "Hello from thread 19\n",
            "Hello from thread 20\n",
            "Hello from thread 21\n",
            "Hello from thread 22\n",
            "Hello from thread 23\n",
            "Hello from thread 24\n",
            "Hello from thread 25\n",
            "Hello from thread 26\n",
            "Hello from thread 27\n",
            "Hello from thread 28\n",
            "Hello from thread 29\n",
            "Hello from thread 30\n",
            "Hello from thread 31\n",
            "Hello from thread 32\n",
            "Hello from thread 33\n",
            "Hello from thread 34\n",
            "Hello from thread 35\n",
            "Hello from thread 36\n",
            "Hello from thread 37\n",
            "Hello from thread 38\n",
            "Hello from thread 39\n",
            "Hello from thread 40\n",
            "Hello from thread 41\n",
            "Hello from thread 42\n",
            "Hello from thread 43\n",
            "Hello from thread 44\n",
            "Hello from thread 45\n",
            "Hello from thread 46\n",
            "Hello from thread 47\n",
            "Hello from thread 48\n",
            "Hello from thread 49\n",
            "Hello from thread 50\n",
            "Hello from thread 51\n",
            "Hello from thread 52\n",
            "Hello from thread 53\n",
            "Hello from thread 54\n",
            "Hello from thread 55\n",
            "Hello from thread 56\n",
            "Hello from thread 57\n",
            "Hello from thread 58\n",
            "Hello from thread 59\n",
            "Hello from thread 60\n",
            "Hello from thread 61\n",
            "Hello from thread 62\n",
            "Hello from thread 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Vektor szorzása konstansal*"
      ],
      "metadata": {
        "id": "-TE3eg-ZzF89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vektor_osszeadas.cu\n",
        "# include <stdio.h>\n",
        "# include <cuda_runtime.h>\n",
        "\n",
        "// GPU kernel - minden szál egy elemet dolgoz fel\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000;\n",
        "    int size = n * sizeof(int);\n",
        "\n",
        "    // Host memória foglalása\n",
        "    int *h_a = (int *)malloc(size);\n",
        "    int *h_b = (int *)malloc(size);\n",
        "    int *h_c = (int *)malloc(size);\n",
        "\n",
        "    // Vektorok inicializálása\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i;\n",
        "    }\n",
        "\n",
        "    // Device memória foglalása\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // Adatok másolása a host-ról a device-ra\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel indítása 256 szállal blokkonként\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    // Eredmény visszamásolása a device-ról a host-ra\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Eredmény ellenőrzése\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Memória felszabadítása\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBUKeCF50OIZ",
        "outputId": "a19ba722-c511-4cbc-8416-7c3f21b42d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vektor_osszeadas.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vektor_osszeadas.cu"
      ],
      "metadata": {
        "id": "qqai47bm3Nav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_ta_phm3Rlw",
        "outputId": "69e14f20-7b53-4b7f-b2df-de72ecd9c7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 + 0 = 0\n",
            "1 + 1 = 2\n",
            "2 + 2 = 4\n",
            "3 + 3 = 6\n",
            "4 + 4 = 8\n",
            "5 + 5 = 10\n",
            "6 + 6 = 12\n",
            "7 + 7 = 14\n",
            "8 + 8 = 16\n",
            "9 + 9 = 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vektor_konstans_szorzas.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "\n",
        "__global__ void vector_multiply_with_constant(float* a, float* b, float k, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        b[i] = a[i] * k;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main () {\n",
        "  int n = 100000;\n",
        "  int size = n * sizeof(int);\n",
        "  float k = 2.5;\n",
        "\n",
        "  // Host memria foglalása\n",
        "  float *h_a = (float *)malloc(size);\n",
        "  float *h_b = (float *)malloc(size);\n",
        "\n",
        "  srand(time(0));\n",
        "\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    h_a[i] = rand() / (float)RAND_MAX;\n",
        "  }\n",
        "\n",
        "  // Device memoria foglalása\n",
        "  float *d_a, *d_b;\n",
        "  cudaMalloc(&d_a, size);\n",
        "  cudaMalloc(&d_b, size);\n",
        "\n",
        "  // Adatok masolása a host-ról a device-ra\n",
        "  cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threadsPerBlock = 256;\n",
        "  int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  vector_multiply_with_constant<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, k, n);\n",
        "\n",
        "  // Copy back from device to host\n",
        "  cudaMemcpy(h_b, d_b, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "   float max_val = h_b[0];\n",
        "  for(int i = 1; i < n; i++) {\n",
        "      if (h_b[i] > max_val) {\n",
        "          max_val = h_b[i];\n",
        "      }\n",
        "  }\n",
        "\n",
        "  std::cout << \"Max value: \" << max_val << std::endl;\n",
        "\n",
        "    // Free allocated memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "\n",
        "  return 0;\n",
        "\n",
        "\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJTZua4ExNUd",
        "outputId": "9b8e99d1-3185-43bd-8835-cb51bd4c13dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vektor_konstans_szorzas.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vektor_konstans_szorzas.cu"
      ],
      "metadata": {
        "id": "Rc3YuLAD2LYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUUQN1Rq2vI4",
        "outputId": "82b44cf2-a33e-488e-c79f-8d465e6ea169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max value: 2.49999\n"
          ]
        }
      ]
    }
  ]
}